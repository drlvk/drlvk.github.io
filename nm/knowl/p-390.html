<!DOCTYPE html>
<html lang="en-US">
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2020-11-15T23:01:53-05:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<h6 class="heading"><span class="type">Paragraph</span></h6>
<p>If we keep the starting point <code class="code-inline tex2jax_ignore">[1; 2; 3]</code> in <a class="xref" data-knowl="./knowl/example-durand-kerner-broyden.html" title="Example 11.4.1: Use Broyden's method to find all roots of a cubic polynomial">Example 11.4.1</a> but change the initial guess for inverse Jacobian to the matrix</p>
<pre class="code-block tex2jax_ignore">
B = 0.1*eye(3);
</pre>
<p data-braille="continuation">the algorithm converges much faster: in 53 steps. Why could this be? In what way does the “smaller” matrix help? Is the factor of 0.1 an under-relaxation parameter here?</p>
<span class="incontext"><a href="examples-broyden.html#p-390">in-context</a></span>
</body>
</html>
