<!DOCTYPE html>
<html lang="en-US">
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2021-02-10T20:02:15-05:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<h6 class="heading"><span class="type">Paragraph</span></h6>
<p>One way to improve the situation is to run a one-variable minimization algorithm, <dfn class="terminology">line search</dfn> at each step, to find the minimum of \(f\) on the line of steepest descent. This means minimizing the function \(h(t) = f(\mathbf a + t \mathbf g)\) where \(\mathbf g = -\nabla f(\mathbf a)\text{.}\) If we find the exact minimum on the line each time, then the minimization process for function converges to the minimum quickly. But for slightly more complicated functions the difficulty emerges again. Consider <a class="external" href="https://en.wikipedia.org/wiki/Rosenbrock_function" target="_blank">Rosenbrock's function</a></p>
<div class="displaymath">
\begin{equation}
f(\mathbf x) = (x_1 - 1)^2 + 100(x_1^2 - x_2)^2\tag{32.1.2}
\end{equation}
</div>
<p data-braille="continuation">Its graph has a curved “valley” along the parabola \(x_2 = x_1^2\text{.}\) One-dimensional minimization along the line of steepest descent leads to each consecutive direction being perpendicular to the previous one (why?). So the algorithm ends up zig-zagging in tiny steps in the deep narrow valley, making very little progress toward minimum. And since each step is its own minimization problem (in one dimension), the entire process may take too long.</p>
<span class="incontext"><a href="section-gradient-descent-nd.html#p-886">in-context</a></span>
</body>
</html>
